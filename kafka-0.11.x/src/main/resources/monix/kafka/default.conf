kafka {
  bootstrap.servers = "localhost:9092"
  client.id = ""

  # E.g. "org.apache.kafka.clients.producer.internals.DefaultPartitioner"
  partitioner.class = null

  acks = "1"
  buffer.memory = 33554432
  compression.type = "none"
  retries = 0

  ssl.key.password = null
  ssl.keystore.password = null
  ssl.keystore.location = null
  ssl.truststore.password = null
  ssl.truststore.location = null

  batch.size = 16384
  connections.max.idle.ms = 540000
  linger.ms = 0
  max.block.ms = 60000
  max.request.size = 1048576

  receive.buffer.bytes = 32768
  request.timeout.ms = 40000

  sasl.kerberos.service.name = null
  sasl.mechanism = "GSSAPI"

  security.protocol = "PLAINTEXT"
  send.buffer.bytes = 131072
  ssl.enabled.protocols = "TLSv1.2,TLSv1.1,TLSv1"
  ssl.keystore.type = "JKS"
  ssl.protocol = "TLS"
  ssl.provider = null
  ssl.truststore.type = "JKS"

  reconnect.backoff.ms = 50
  retry.backoff.ms = 100

  metadata.max.age.ms = 300000

  # Consumer specific settings

  fetch.min.bytes = 1
  group.id = ""
  heartbeat.interval.ms = 3000
  max.partition.fetch.bytes = 1048576
  session.timeout.ms = 30000
  auto.offset.reset = "latest"
  enable.auto.commit = true
  exclude.internal.topics = true
  max.poll.records = 2147483647
  receive.buffer.bytes = 65536
  check.crcs = true
  fetch.max.wait.ms = 500
  max.poll.records = 1
  max.poll.interval.ms = 3000

  # Monix specific settings

  # Number of requests that KafkaProducerSink
  # can push in parallel
  monix.producer.sink.parallelism = 100
  # Triggers a seekToEnd when the observable starts
  monix.observable.seekEnd.onStart = false
  # Possible values: sync, async
  monix.observable.commit.type = "sync"
  # Possible values: before-ack, after-ack or no-ack
  monix.observable.commit.order = "after-ack"
}